Learning rate: 0.010000
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[0,    10] loss: 4.651
[0,    20] loss: 4.602
[0,    30] loss: 4.551
[0,    40] loss: 4.468
[0,    50] loss: 4.396
[0,    60] loss: 4.325
[0,    70] loss: 4.249
[0,    80] loss: 4.209
[0,    90] loss: 4.199
[0,   100] loss: 4.144
[1,    10] loss: 4.252
[1,    20] loss: 4.112
[1,    30] loss: 3.991
[1,    40] loss: 4.026
[1,    50] loss: 4.016
[1,    60] loss: 3.989
[1,    70] loss: 3.976
[1,    80] loss: 3.972
[1,    90] loss: 3.913
[1,   100] loss: 3.882
[2,    10] loss: 4.206
[2,    20] loss: 3.990
[2,    30] loss: 3.989
[2,    40] loss: 3.942
[2,    50] loss: 3.996
[2,    60] loss: 3.896
[2,    70] loss: 3.926
[2,    80] loss: 3.846
[2,    90] loss: 3.817
[2,   100] loss: 3.818
[3,    10] loss: 4.108
[3,    20] loss: 4.017
[3,    30] loss: 3.945
[3,    40] loss: 3.892
[3,    50] loss: 3.823
[3,    60] loss: 3.900
[3,    70] loss: 3.820
[3,    80] loss: 3.835
[3,    90] loss: 3.842
[3,   100] loss: 3.907
[4,    10] loss: 3.877
[4,    20] loss: 3.853
[4,    30] loss: 3.880
[4,    40] loss: 3.862
[4,    50] loss: 3.781
[4,    60] loss: 3.800
[4,    70] loss: 3.820
[4,    80] loss: 3.868
[4,    90] loss: 3.890
[4,   100] loss: 3.874
[5,    10] loss: 3.990
[5,    20] loss: 3.921
[5,    30] loss: 3.824
[5,    40] loss: 3.753
[5,    50] loss: 3.747
[5,    60] loss: 3.801
[5,    70] loss: 3.780
[5,    80] loss: 3.706
[5,    90] loss: 3.746
[5,   100] loss: 3.740
[6,    10] loss: 3.973
[6,    20] loss: 3.968
[6,    30] loss: 3.894
[6,    40] loss: 3.862
[6,    50] loss: 3.824
[6,    60] loss: 3.922
[6,    70] loss: 3.828
[6,    80] loss: 3.864
[6,    90] loss: 3.855
[6,   100] loss: 3.757
[7,    10] loss: 3.944
[7,    20] loss: 3.860
[7,    30] loss: 3.906
[7,    40] loss: 3.758
[7,    50] loss: 3.776
[7,    60] loss: 3.721
[7,    70] loss: 3.723
[7,    80] loss: 3.734
[7,    90] loss: 3.721
[7,   100] loss: 3.782
[8,    10] loss: 3.802
[8,    20] loss: 3.741
[8,    30] loss: 3.746
[8,    40] loss: 3.698
[8,    50] loss: 3.721
[8,    60] loss: 3.729
[8,    70] loss: 3.669
[8,    80] loss: 3.713
[8,    90] loss: 3.621
[8,   100] loss: 3.662
[9,    10] loss: 4.100
[9,    20] loss: 4.081
[9,    30] loss: 3.903
[9,    40] loss: 3.831
[9,    50] loss: 3.750
[9,    60] loss: 3.725
[9,    70] loss: 3.700
[9,    80] loss: 3.686
[9,    90] loss: 3.720
[9,   100] loss: 3.728
[10,    10] loss: 4.065
[10,    20] loss: 3.940
[10,    30] loss: 3.803
[10,    40] loss: 3.840
[10,    50] loss: 3.773
[10,    60] loss: 3.784
[10,    70] loss: 3.704
[10,    80] loss: 3.837
[10,    90] loss: 3.725
[10,   100] loss: 3.804
[11,    10] loss: 3.874
[11,    20] loss: 3.836
[11,    30] loss: 3.701
[11,    40] loss: 3.731
[11,    50] loss: 3.873
[11,    60] loss: 3.744
[11,    70] loss: 3.707
[11,    80] loss: 3.734
[11,    90] loss: 3.639
[11,   100] loss: 3.677
[12,    10] loss: 3.728
[12,    20] loss: 3.789
[12,    30] loss: 3.790
[12,    40] loss: 3.780
[12,    50] loss: 3.688
[12,    60] loss: 3.764
[12,    70] loss: 3.692
[12,    80] loss: 3.621
[12,    90] loss: 3.772
[12,   100] loss: 3.666
[13,    10] loss: 3.991
[13,    20] loss: 3.911
[13,    30] loss: 3.927
[13,    40] loss: 3.822
[13,    50] loss: 3.772
[13,    60] loss: 3.727
[13,    70] loss: 3.794
[13,    80] loss: 3.706
[13,    90] loss: 3.760
[13,   100] loss: 3.750
[14,    10] loss: 3.876
[14,    20] loss: 3.794
[14,    30] loss: 3.733
[14,    40] loss: 3.726
[14,    50] loss: 3.840
[14,    60] loss: 3.691
[14,    70] loss: 3.665
[14,    80] loss: 3.749
[14,    90] loss: 3.757
[14,   100] loss: 3.677
Learning rate: 0.001000
[15,    10] loss: 3.844
[15,    20] loss: 3.669
[15,    30] loss: 3.612
[15,    40] loss: 3.591
[15,    50] loss: 3.541
[15,    60] loss: 3.550
[15,    70] loss: 3.472
[15,    80] loss: 3.443
[15,    90] loss: 3.531
[15,   100] loss: 3.493
[16,    10] loss: 3.589
[16,    20] loss: 3.457
[16,    30] loss: 3.481
[16,    40] loss: 3.505
[16,    50] loss: 3.533
[16,    60] loss: 3.503
[16,    70] loss: 3.523
[16,    80] loss: 3.409
[16,    90] loss: 3.449
[16,   100] loss: 3.469
[17,    10] loss: 3.486
[17,    20] loss: 3.399
[17,    30] loss: 3.494
[17,    40] loss: 3.400
[17,    50] loss: 3.402
[17,    60] loss: 3.489
[17,    70] loss: 3.446
[17,    80] loss: 3.512
[17,    90] loss: 3.554
[17,   100] loss: 3.529
[18,    10] loss: 3.433
[18,    20] loss: 3.489
[18,    30] loss: 3.412
[18,    40] loss: 3.418
[18,    50] loss: 3.438
[18,    60] loss: 3.454
[18,    70] loss: 3.516
[18,    80] loss: 3.465
[18,    90] loss: 3.478
[18,   100] loss: 3.498
[19,    10] loss: 3.464
[19,    20] loss: 3.409
[19,    30] loss: 3.406
[19,    40] loss: 3.458
[19,    50] loss: 3.509
[19,    60] loss: 3.491
[19,    70] loss: 3.399
[19,    80] loss: 3.506
[19,    90] loss: 3.392
[19,   100] loss: 3.464