Learning rate: 0.010000
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[0,    10] loss: 4.592
[0,    20] loss: 3.830
[0,    30] loss: 2.977
[0,    40] loss: 2.322
[0,    50] loss: 1.745
[0,    60] loss: 1.448
[0,    70] loss: 1.212
[0,    80] loss: 1.115
[0,    90] loss: 0.994
[0,   100] loss: 0.838
[1,    10] loss: 0.805
[1,    20] loss: 0.674
[1,    30] loss: 0.597
[1,    40] loss: 0.549
[1,    50] loss: 0.510
[1,    60] loss: 0.519
[1,    70] loss: 0.524
[1,    80] loss: 0.476
[1,    90] loss: 0.466
[1,   100] loss: 0.495
[2,    10] loss: 0.586
[2,    20] loss: 0.463
[2,    30] loss: 0.409
[2,    40] loss: 0.373
[2,    50] loss: 0.337
[2,    60] loss: 0.336
[2,    70] loss: 0.312
[2,    80] loss: 0.274
[2,    90] loss: 0.306
[2,   100] loss: 0.288
[3,    10] loss: 0.331
[3,    20] loss: 0.249
[3,    30] loss: 0.263
[3,    40] loss: 0.219
[3,    50] loss: 0.208
[3,    60] loss: 0.207
[3,    70] loss: 0.216
[3,    80] loss: 0.194
[3,    90] loss: 0.196
[3,   100] loss: 0.192
[4,    10] loss: 0.187
[4,    20] loss: 0.167
[4,    30] loss: 0.160
[4,    40] loss: 0.164
[4,    50] loss: 0.136
[4,    60] loss: 0.126
[4,    70] loss: 0.120
[4,    80] loss: 0.126
[4,    90] loss: 0.125
[4,   100] loss: 0.114
Learning rate: 0.010000
[5,    10] loss: 0.214
[5,    20] loss: 0.215
[5,    30] loss: 0.163
[5,    40] loss: 0.145
[5,    50] loss: 0.124
[5,    60] loss: 0.107
[5,    70] loss: 0.112
[5,    80] loss: 0.101
[5,    90] loss: 0.113
[5,   100] loss: 0.124
[6,    10] loss: 0.358
[6,    20] loss: 0.322
[6,    30] loss: 0.218
[6,    40] loss: 0.177
[6,    50] loss: 0.160
[6,    60] loss: 0.150
[6,    70] loss: 0.126
[6,    80] loss: 0.130
[6,    90] loss: 0.109
[6,   100] loss: 0.099
[7,    10] loss: 0.250
[7,    20] loss: 0.212
[7,    30] loss: 0.151
[7,    40] loss: 0.138
[7,    50] loss: 0.125
[7,    60] loss: 0.127
[7,    70] loss: 0.103
[7,    80] loss: 0.117
[7,    90] loss: 0.088
[7,   100] loss: 0.100
[8,    10] loss: 0.272
[8,    20] loss: 0.157
[8,    30] loss: 0.189
[8,    40] loss: 0.129
[8,    50] loss: 0.097
[8,    60] loss: 0.094
[8,    70] loss: 0.080
[8,    80] loss: 0.062
[8,    90] loss: 0.075
[8,   100] loss: 0.066
[9,    10] loss: 0.163
[9,    20] loss: 0.164
[9,    30] loss: 0.128
[9,    40] loss: 0.112
[9,    50] loss: 0.089
[9,    60] loss: 0.073
[9,    70] loss: 0.080
[9,    80] loss: 0.065
[9,    90] loss: 0.057
[9,   100] loss: 0.056
[10,    10] loss: 0.185
[10,    20] loss: 0.120
[10,    30] loss: 0.110
[10,    40] loss: 0.085
[10,    50] loss: 0.067
[10,    60] loss: 0.060
[10,    70] loss: 0.056
[10,    80] loss: 0.055
[10,    90] loss: 0.053
[10,   100] loss: 0.059
[11,    10] loss: 0.218
[11,    20] loss: 0.183
[11,    30] loss: 0.142
[11,    40] loss: 0.085
[11,    50] loss: 0.066
[11,    60] loss: 0.059
[11,    70] loss: 0.046
[11,    80] loss: 0.051
[11,    90] loss: 0.052
[11,   100] loss: 0.050
[12,    10] loss: 0.056
[12,    20] loss: 0.059
[12,    30] loss: 0.041
[12,    40] loss: 0.045
[12,    50] loss: 0.034
[12,    60] loss: 0.030
[12,    70] loss: 0.033
[12,    80] loss: 0.030
[12,    90] loss: 0.022
[12,   100] loss: 0.029
[13,    10] loss: 0.251
[13,    20] loss: 0.158
[13,    30] loss: 0.128
[13,    40] loss: 0.114
[13,    50] loss: 0.078
[13,    60] loss: 0.064
[13,    70] loss: 0.060
[13,    80] loss: 0.064
[13,    90] loss: 0.051
[13,   100] loss: 0.045
[14,    10] loss: 0.198
[14,    20] loss: 0.186
[14,    30] loss: 0.130
[14,    40] loss: 0.096
[14,    50] loss: 0.073
[14,    60] loss: 0.064
[14,    70] loss: 0.058
[14,    80] loss: 0.040
[14,    90] loss: 0.035
[14,   100] loss: 0.036
Learning rate: 0.001000
[15,    10] loss: 0.035
[15,    20] loss: 0.030
[15,    30] loss: 0.028
[15,    40] loss: 0.028
[15,    50] loss: 0.026
[15,    60] loss: 0.026
[15,    70] loss: 0.026
[15,    80] loss: 0.024
[15,    90] loss: 0.025
[15,   100] loss: 0.025
[16,    10] loss: 0.024
[16,    20] loss: 0.024
[16,    30] loss: 0.025
[16,    40] loss: 0.029
[16,    50] loss: 0.025
[16,    60] loss: 0.023
[16,    70] loss: 0.023
[16,    80] loss: 0.020
[16,    90] loss: 0.024
[16,   100] loss: 0.026
[17,    10] loss: 0.024
[17,    20] loss: 0.024
[17,    30] loss: 0.024
[17,    40] loss: 0.022
[17,    50] loss: 0.027
[17,    60] loss: 0.027
[17,    70] loss: 0.022
[17,    80] loss: 0.018
[17,    90] loss: 0.016
[17,   100] loss: 0.021
[18,    10] loss: 0.021
[18,    20] loss: 0.021
[18,    30] loss: 0.021
[18,    40] loss: 0.019
[18,    50] loss: 0.022
[18,    60] loss: 0.017
[18,    70] loss: 0.019
[18,    80] loss: 0.017
[18,    90] loss: 0.018
[18,   100] loss: 0.021
[19,    10] loss: 0.017
[19,    20] loss: 0.019
[19,    30] loss: 0.018
[19,    40] loss: 0.016
[19,    50] loss: 0.019
[19,    60] loss: 0.016
[19,    70] loss: 0.017
[19,    80] loss: 0.022
[19,    90] loss: 0.020
[19,   100] loss: 0.015