Learning rate: 0.100000
/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
[0,    10] loss: 4.575
[0,    20] loss: 4.310
[0,    30] loss: 4.055
[0,    40] loss: 4.002
[0,    50] loss: 3.864
[0,    60] loss: 3.713
[0,    70] loss: 3.599
[0,    80] loss: 3.521
[0,    90] loss: 3.419
[0,   100] loss: 3.355
[1,    10] loss: 3.658
[1,    20] loss: 3.516
[1,    30] loss: 3.238
[1,    40] loss: 3.170
[1,    50] loss: 3.059
[1,    60] loss: 3.044
[1,    70] loss: 3.012
[1,    80] loss: 2.932
[1,    90] loss: 2.999
[1,   100] loss: 2.900
[2,    10] loss: 3.086
[2,    20] loss: 3.050
[2,    30] loss: 2.878
[2,    40] loss: 2.791
[2,    50] loss: 2.704
[2,    60] loss: 2.653
[2,    70] loss: 2.698
[2,    80] loss: 2.542
[2,    90] loss: 2.632
[2,   100] loss: 2.609
[3,    10] loss: 3.022
[3,    20] loss: 2.767
[3,    30] loss: 2.653
[3,    40] loss: 2.532
[3,    50] loss: 2.327
[3,    60] loss: 2.418
[3,    70] loss: 2.319
[3,    80] loss: 2.344
[3,    90] loss: 2.379
[3,   100] loss: 2.325
[4,    10] loss: 2.766
[4,    20] loss: 2.458
[4,    30] loss: 2.322
[4,    40] loss: 2.289
[4,    50] loss: 2.190
[4,    60] loss: 2.297
[4,    70] loss: 2.209
[4,    80] loss: 2.169
[4,    90] loss: 2.201
[4,   100] loss: 2.167
Learning rate: 0.010000
[5,    10] loss: 2.003
[5,    20] loss: 1.927
[5,    30] loss: 1.880
[5,    40] loss: 1.794
[5,    50] loss: 1.801
[5,    60] loss: 1.853
[5,    70] loss: 1.784
[5,    80] loss: 1.811
[5,    90] loss: 1.692
[5,   100] loss: 1.667
[6,    10] loss: 1.718
[6,    20] loss: 1.766
[6,    30] loss: 1.667
[6,    40] loss: 1.692
[6,    50] loss: 1.696
[6,    60] loss: 1.755
[6,    70] loss: 1.623
[6,    80] loss: 1.654
[6,    90] loss: 1.720
[6,   100] loss: 1.658
[7,    10] loss: 1.681
[7,    20] loss: 1.612
[7,    30] loss: 1.626
[7,    40] loss: 1.644
[7,    50] loss: 1.605
[7,    60] loss: 1.707
[7,    70] loss: 1.649
[7,    80] loss: 1.644
[7,    90] loss: 1.576
[7,   100] loss: 1.522
[8,    10] loss: 1.562
[8,    20] loss: 1.592
[8,    30] loss: 1.645
[8,    40] loss: 1.559
[8,    50] loss: 1.593
[8,    60] loss: 1.644
[8,    70] loss: 1.586
[8,    80] loss: 1.570
[8,    90] loss: 1.529
[8,   100] loss: 1.585
[9,    10] loss: 1.609
[9,    20] loss: 1.596
[9,    30] loss: 1.562
[9,    40] loss: 1.555
[9,    50] loss: 1.562
[9,    60] loss: 1.497
[9,    70] loss: 1.533
[9,    80] loss: 1.530
[9,    90] loss: 1.557
[9,   100] loss: 1.476
[10,    10] loss: 1.553
[10,    20] loss: 1.527
[10,    30] loss: 1.473
[10,    40] loss: 1.532
[10,    50] loss: 1.530
[10,    60] loss: 1.521
[10,    70] loss: 1.426
[10,    80] loss: 1.568
[10,    90] loss: 1.469
[10,   100] loss: 1.414
[11,    10] loss: 1.501
[11,    20] loss: 1.456
[11,    30] loss: 1.514
[11,    40] loss: 1.401
[11,    50] loss: 1.473
[11,    60] loss: 1.435
[11,    70] loss: 1.440
[11,    80] loss: 1.486
[11,    90] loss: 1.493
[11,   100] loss: 1.424
[12,    10] loss: 1.431
[12,    20] loss: 1.399
[12,    30] loss: 1.438
[12,    40] loss: 1.397
[12,    50] loss: 1.448
[12,    60] loss: 1.374
[12,    70] loss: 1.391
[12,    80] loss: 1.424
[12,    90] loss: 1.406
[12,   100] loss: 1.413
[13,    10] loss: 1.459
[13,    20] loss: 1.390
[13,    30] loss: 1.364
[13,    40] loss: 1.384
[13,    50] loss: 1.359
[13,    60] loss: 1.442
[13,    70] loss: 1.337
[13,    80] loss: 1.373
[13,    90] loss: 1.431
[13,   100] loss: 1.394
[14,    10] loss: 1.467
[14,    20] loss: 1.436
[14,    30] loss: 1.409
[14,    40] loss: 1.400
[14,    50] loss: 1.411
[14,    60] loss: 1.365
[14,    70] loss: 1.375
[14,    80] loss: 1.347
[14,    90] loss: 1.295
[14,   100] loss: 1.367
Learning rate: 0.001000
[15,    10] loss: 1.262
[15,    20] loss: 1.200
[15,    30] loss: 1.297
[15,    40] loss: 1.215
[15,    50] loss: 1.286
[15,    60] loss: 1.264
[15,    70] loss: 1.184
[15,    80] loss: 1.269
[15,    90] loss: 1.322
[15,   100] loss: 1.324
[16,    10] loss: 1.185
[16,    20] loss: 1.224
[16,    30] loss: 1.279
[16,    40] loss: 1.289
[16,    50] loss: 1.231
[16,    60] loss: 1.224
[16,    70] loss: 1.265
[16,    80] loss: 1.229
[16,    90] loss: 1.222
[16,   100] loss: 1.185
[17,    10] loss: 1.181
[17,    20] loss: 1.267
[17,    30] loss: 1.223
[17,    40] loss: 1.284
[17,    50] loss: 1.236
[17,    60] loss: 1.162
[17,    70] loss: 1.244
[17,    80] loss: 1.307
[17,    90] loss: 1.204
[17,   100] loss: 1.233
[18,    10] loss: 1.254
[18,    20] loss: 1.242
[18,    30] loss: 1.241
[18,    40] loss: 1.184
[18,    50] loss: 1.273
[18,    60] loss: 1.234
[18,    70] loss: 1.133
[18,    80] loss: 1.211
[18,    90] loss: 1.169
[18,   100] loss: 1.294
[19,    10] loss: 1.185
[19,    20] loss: 1.239
[19,    30] loss: 1.256
[19,    40] loss: 1.250
[19,    50] loss: 1.265
[19,    60] loss: 1.185
[19,    70] loss: 1.176
[19,    80] loss: 1.232
[19,    90] loss: 1.178
[19,   100] loss: 1.247